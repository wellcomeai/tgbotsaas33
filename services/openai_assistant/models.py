"""
OpenAI Responses API Models
‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ OpenAI Responses API
‚úÖ –ù–û–í–û–ï: –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
‚úÖ –ù–û–í–û–ï: –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏ –∏ Vector Store
"""

from dataclasses import dataclass
from typing import Optional, Dict, Any, List, Union
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


@dataclass
class OpenAIResponsesRequest:
    """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –ó–∞–ø—Ä–æ—Å –¥–ª—è Responses API"""
    bot_id: str
    agent_name: str
    agent_role: str
    system_prompt: Optional[str] = None
    model: str = "gpt-4o"
    temperature: float = 0.7
    max_tokens: int = 4000
    
    # ‚úÖ –ù–û–í–´–ï –ü–û–õ–Ø –î–õ–Ø RESPONSES API
    store_conversations: bool = True           # –•—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ OpenAI
    conversation_retention: int = 30           # –î–Ω–∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è (1-90)
    enable_streaming: bool = True              # –ü–æ—Ç–æ–∫–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã
    
    # ‚úÖ –í–°–¢–†–û–ï–ù–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ RESPONSES API
    enable_web_search: bool = False            # –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –≤–µ–±-–ø–æ–∏—Å–∫ OpenAI
    enable_code_interpreter: bool = False      # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä –∫–æ–¥–∞
    enable_file_search: bool = False           # –ü–æ–∏—Å–∫ –ø–æ —Ñ–∞–π–ª–∞–º
    enable_image_generation: bool = False      # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    vector_store_ids: Optional[List[str]] = None  # ID –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â –¥–ª—è file_search
    
    # ‚úÖ –ù–û–í–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò
    computer_use_enabled: bool = False         # Computer use (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ)
    reasoning_effort: str = 'medium'           # –î–ª—è o-series –º–æ–¥–µ–ª–µ–π (low/medium/high)
    
    def to_agent(self) -> 'OpenAIResponsesAgent':
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ OpenAIResponsesAgent"""
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        tools = []
        if self.enable_web_search:
            tools.append('web_search_preview')
        if self.enable_code_interpreter:
            tools.append('code_interpreter')
        if self.enable_file_search:
            tools.append('file_search')
        if self.enable_image_generation:
            tools.append('image_generation')
        if self.computer_use_enabled:
            tools.append('computer_use_preview')
        
        return OpenAIResponsesAgent(
            bot_id=self.bot_id,
            agent_name=self.agent_name,
            agent_role=self.agent_role,
            system_prompt=self.system_prompt or f"–¢—ã - {self.agent_role}. –¢–≤–æ–µ –∏–º—è {self.agent_name}. –û—Ç–≤–µ—á–∞–π –ø–æ–ª–µ–∑–Ω–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ.",
            model=self.model,
            temperature=self.temperature,
            max_tokens=self.max_tokens,
            store_conversations=self.store_conversations,
            conversation_retention=self.conversation_retention,
            enable_streaming=self.enable_streaming,
            tools=tools,
            vector_store_ids=self.vector_store_ids or [],
            reasoning_effort=self.reasoning_effort
        )


@dataclass 
class OpenAIResponsesAgent:
    """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –ú–æ–¥–µ–ª—å –∞–≥–µ–Ω—Ç–∞ –¥–ª—è Responses API"""
    id: Optional[int] = None
    bot_id: Optional[str] = None
    agent_name: str = ""
    agent_role: str = ""
    system_prompt: str = ""
    model: str = "gpt-4o"
    temperature: float = 0.7
    max_tokens: int = 4000
    is_active: bool = True
    
    # ‚úÖ RESPONSES API CORE SETTINGS
    store_conversations: bool = True           # –•—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
    conversation_retention: int = 30           # –î–Ω–∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è (1-90)
    enable_streaming: bool = True              # –ü–æ—Ç–æ–∫–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã
    tools: List[str] = None                    # –í–∫–ª—é—á–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    
    # ‚úÖ –ù–û–í–´–ï –ü–û–õ–Ø –î–õ–Ø RESPONSES API
    vector_store_ids: List[str] = None         # ID –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â –¥–ª—è file_search
    reasoning_effort: str = 'medium'           # –£—Ä–æ–≤–µ–Ω—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è o-series –º–æ–¥–µ–ª–µ–π
    computer_use_enabled: bool = False         # Computer use (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ)
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    openai_assistant_id: Optional[str] = None  # –õ–æ–∫–∞–ª—å–Ω—ã–π ID –∞–≥–µ–Ω—Ç–∞ (–Ω–µ OpenAI Assistant)
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
    
    def __post_init__(self):
        if self.tools is None:
            self.tools = []
        if self.vector_store_ids is None:
            self.vector_store_ids = []
    
    def to_responses_config(self) -> Dict[str, Any]:
        """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è Responses API"""
        config = {
            "model": self.model,
            "store": self.store_conversations,
            "stream": self.enable_streaming,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
        }
        
        # ‚úÖ –î–û–ë–ê–í–õ–Ø–ï–ú –í–°–¢–†–û–ï–ù–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ RESPONSES API
        if self.tools:
            tools_config = []
            for tool in self.tools:
                if tool == 'web_search_preview':
                    tools_config.append({"type": "web_search_preview"})
                elif tool == 'code_interpreter':
                    tools_config.append({
                        "type": "code_interpreter",
                        "container": {"type": "auto"}
                    })
                elif tool == 'file_search':
                    if self.vector_store_ids:
                        tools_config.append({
                            "type": "file_search",
                            "vector_store_ids": self.vector_store_ids
                        })
                elif tool == 'image_generation':
                    tools_config.append({"type": "image_generation"})
                elif tool == 'computer_use_preview':
                    tools_config.append({"type": "computer_use_preview"})
            
            if tools_config:
                config["tools"] = tools_config
        
        # ‚úÖ –î–û–ë–ê–í–õ–Ø–ï–ú REASONING EFFORT –î–õ–Ø O-SERIES –ú–û–î–ï–õ–ï–ô
        if self.model.startswith('o1'):
            config["reasoning_effort"] = self.reasoning_effort
        
        return config
    
    def get_system_instructions(self) -> str:
        """‚úÖ –ù–û–í–û–ï: –ü–æ–ª—É—á–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è Responses API"""
        return self.system_prompt
    
    def has_tool(self, tool_name: str) -> bool:
        """‚úÖ –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∫–ª—é—á–µ–Ω –ª–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç"""
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        tool_mapping = {
            'web_search': 'web_search_preview',
            'web_search_preview': 'web_search_preview',
            'code_interpreter': 'code_interpreter',
            'file_search': 'file_search',
            'image_generation': 'image_generation',
            'computer_use': 'computer_use_preview',
            'computer_use_preview': 'computer_use_preview'
        }
        
        normalized_tool = tool_mapping.get(tool_name, tool_name)
        return normalized_tool in self.tools
    
    def add_tool(self, tool_name: str, vector_store_ids: List[str] = None) -> bool:
        """‚úÖ –ù–û–í–û–ï: –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç"""
        valid_tools = ['web_search_preview', 'code_interpreter', 'file_search', 'image_generation', 'computer_use_preview']
        
        if tool_name not in valid_tools:
            return False
        
        if tool_name not in self.tools:
            self.tools.append(tool_name)
        
        # –î–ª—è file_search –¥–æ–±–∞–≤–ª—è–µ–º vector_store_ids
        if tool_name == 'file_search' and vector_store_ids:
            self.vector_store_ids.extend(vector_store_ids)
            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            self.vector_store_ids = list(set(self.vector_store_ids))
        
        return True
    
    def remove_tool(self, tool_name: str) -> bool:
        """‚úÖ –ù–û–í–û–ï: –£–¥–∞–ª–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç"""
        if tool_name in self.tools:
            self.tools.remove(tool_name)
            
            # –ï—Å–ª–∏ —É–¥–∞–ª—è–µ–º file_search, –æ—á–∏—â–∞–µ–º vector_store_ids
            if tool_name == 'file_search':
                self.vector_store_ids = []
            
            return True
        return False
    
    def validate_tools(self) -> tuple[bool, str]:
        """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        valid_tools = ['web_search_preview', 'code_interpreter', 'file_search', 'image_generation', 'computer_use_preview']
        
        for tool in self.tools:
            if tool not in valid_tools:
                return False, f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {tool}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–ª—è file_search –µ—Å—Ç—å vector_store_ids
        if 'file_search' in self.tools and not self.vector_store_ids:
            return False, "–î–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ file_search –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å vector_store_ids"
        
        return True, ""
    
    def validate_retention(self) -> tuple[bool, str]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤"""
        if not 1 <= self.conversation_retention <= 90:
            return False, "–í—Ä–µ–º—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 1 –¥–æ 90 –¥–Ω–µ–π"
        return True, ""
    
    def validate_reasoning_effort(self) -> tuple[bool, str]:
        """‚úÖ –ù–û–í–û–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
        valid_efforts = ['low', 'medium', 'high']
        if self.reasoning_effort not in valid_efforts:
            return False, f"–£—Ä–æ–≤–µ–Ω—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–¥–Ω–∏–º –∏–∑: {', '.join(valid_efforts)}"
        return True, ""
    
    @classmethod
    def from_db_row(cls, row) -> 'OpenAIResponsesAgent':
        """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –ë–î"""
        tools = []
        vector_store_ids = []
        
        if hasattr(row, 'openai_settings') and row.openai_settings:
            settings = row.openai_settings
            
            # ‚úÖ –û–ë–ù–û–í–õ–ï–ù–ù–û–ï –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–û–í
            if settings.get('enable_web_search'):
                tools.append('web_search_preview')
            if settings.get('enable_code_interpreter'):
                tools.append('code_interpreter')
            if settings.get('enable_file_search'):
                tools.append('file_search')
                vector_store_ids = settings.get('vector_store_ids', [])
            if settings.get('enable_image_generation'):
                tools.append('image_generation')
            if settings.get('computer_use_enabled'):
                tools.append('computer_use_preview')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º agent_role –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        agent_role = "AI –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
        if hasattr(row, 'openai_settings') and row.openai_settings:
            agent_role = row.openai_settings.get('agent_role', agent_role)
        
        return cls(
            id=row.id,
            bot_id=row.bot_id,
            agent_name=row.openai_agent_name or "",
            agent_role=agent_role,
            system_prompt=row.openai_agent_instructions or f"–¢—ã - {row.openai_agent_name or 'AI –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç'}. –û—Ç–≤–µ—á–∞–π –ø–æ–ª–µ–∑–Ω–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ.",
            model=row.openai_model or "gpt-4o",
            temperature=float(row.openai_settings.get('temperature', 0.7)) if row.openai_settings else 0.7,
            max_tokens=row.openai_settings.get('max_tokens', 4000) if row.openai_settings else 4000,
            is_active=row.ai_assistant_enabled,
            store_conversations=getattr(row, 'openai_store_conversations', True),
            conversation_retention=getattr(row, 'openai_conversation_retention_days', 30),
            enable_streaming=row.openai_settings.get('enable_streaming', True) if row.openai_settings else True,
            tools=tools,
            vector_store_ids=vector_store_ids,
            reasoning_effort=row.openai_settings.get('reasoning_effort', 'medium') if row.openai_settings else 'medium',
            computer_use_enabled=row.openai_settings.get('computer_use_enabled', False) if row.openai_settings else False,
            openai_assistant_id=row.openai_agent_id,
            created_at=row.created_at,
            updated_at=row.updated_at
        )


@dataclass
class OpenAIResponsesContext:
    """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è Responses API"""
    user_id: int
    user_name: str
    username: Optional[str] = None
    bot_id: Optional[str] = None
    chat_id: Optional[int] = None
    is_admin: bool = False
    
    # ‚úÖ –£–ë–ò–†–ê–ï–ú previous_response_id –æ—Ç—Å—é–¥–∞ - –æ–Ω —Ç–µ–ø–µ—Ä—å —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    
    def to_context_string(self) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å—Ç—Ä–æ–∫—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π"""
        context_parts = [f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {self.user_name}"]
        
        if self.username:
            context_parts.append(f"Username: @{self.username}")
        
        if self.is_admin:
            context_parts.append("–°—Ç–∞—Ç—É—Å: –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä")
        
        return ". ".join(context_parts)
    
    def prepare_instructions_with_context(self, base_instructions: str) -> str:
        """‚úÖ –ù–û–í–û–ï: –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è Responses API"""
        context_info = self.to_context_string()
        return f"{base_instructions}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞: {context_info}"


@dataclass
class OpenAIResponsesResult:
    """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç Responses API"""
    success: bool
    response_id: Optional[str] = None      # ID –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
    output_text: Optional[str] = None      # –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
    error: Optional[str] = None
    
    # ‚úÖ –ù–û–í–´–ï –ü–û–õ–Ø –î–õ–Ø RESPONSES API
    input_tokens: Optional[int] = None     # –í—Ö–æ–¥—è—â–∏–µ —Ç–æ–∫–µ–Ω—ã  
    output_tokens: Optional[int] = None    # –ò—Å—Ö–æ–¥—è—â–∏–µ —Ç–æ–∫–µ–Ω—ã
    total_tokens: Optional[int] = None     # –û–±—â–∏–µ —Ç–æ–∫–µ–Ω—ã
    response_time: Optional[float] = None  # –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    finish_reason: Optional[str] = None    # –ü—Ä–∏—á–∏–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    model_used: Optional[str] = None       # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    tools_used: Optional[List[str]] = None # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    
    # ‚úÖ –ù–û–í–û–ï: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö
    web_search_results: Optional[List[dict]] = None  # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–±-–ø–æ–∏—Å–∫–∞
    code_executions: Optional[List[dict]] = None     # –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–π –∫–æ–¥
    files_searched: Optional[List[str]] = None       # –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    images_generated: Optional[List[str]] = None     # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    computer_actions: Optional[List[dict]] = None    # –î–µ–π—Å—Ç–≤–∏—è Computer Use
    
    # ‚úÖ –ù–û–í–û–ï: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç–∞
    reasoning_tokens: Optional[int] = None            # –¢–æ–∫–µ–Ω—ã —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (–¥–ª—è o-series)
    reasoning_effort_used: Optional[str] = None       # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
    
    @classmethod
    def success_result(
        cls, 
        response_id: str,
        output_text: str, 
        input_tokens: int = None,
        output_tokens: int = None,
        total_tokens: int = None,
        response_time: float = None,
        finish_reason: str = None,
        model_used: str = None,
        tools_used: List[str] = None,
        **kwargs
    ) -> 'OpenAIResponsesResult':
        """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –°–æ–∑–¥–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        return cls(
            success=True,
            response_id=response_id,
            output_text=output_text,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            total_tokens=total_tokens or (input_tokens or 0) + (output_tokens or 0),
            response_time=response_time,
            finish_reason=finish_reason,
            model_used=model_used,
            tools_used=tools_used or [],
            **kwargs
        )
    
    @classmethod
    def error_result(cls, error: str) -> 'OpenAIResponsesResult':
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –æ—à–∏–±–∫–æ–π"""
        return cls(success=False, error=error)
    
    def to_dict(self) -> Dict[str, Any]:
        """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            'success': self.success,
            'response_id': self.response_id,
            'output_text': self.output_text,
            'error': self.error,
            'input_tokens': self.input_tokens,
            'output_tokens': self.output_tokens,
            'total_tokens': self.total_tokens,
            'response_time': self.response_time,
            'finish_reason': self.finish_reason,
            'model_used': self.model_used,
            'tools_used': self.tools_used,
            'web_search_results': self.web_search_results,
            'code_executions': self.code_executions,
            'files_searched': self.files_searched,
            'images_generated': self.images_generated,
            'computer_actions': self.computer_actions,
            'reasoning_tokens': self.reasoning_tokens,
            'reasoning_effort_used': self.reasoning_effort_used
        }


class OpenAIResponsesConstants:
    """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Responses API"""
    
    # ‚úÖ –ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ï –ú–û–î–ï–õ–ò –î–õ–Ø RESPONSES API
    MODELS = {
        'gpt-4o': 'GPT-4o (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è Responses API)',
        'gpt-4o-mini': 'GPT-4o Mini (–±—ã—Å—Ç—Ä–∞—è –∏ –¥–µ—à–µ–≤–∞—è)',
        'o1-preview': 'o1 Preview (—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è)',
        'o1-mini': 'o1 Mini (–±—ã—Å—Ç—Ä—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è)',
        'gpt-4.1': 'GPT-4.1 (–Ω–æ–≤–µ–π—à–∞—è –º–æ–¥–µ–ª—å)'
    }
    
    DEFAULT_MODEL = 'gpt-4o'
    DEFAULT_TEMPERATURE = 0.7
    DEFAULT_MAX_TOKENS = 4000
    
    # ‚úÖ –í–°–¢–†–û–ï–ù–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ RESPONSES API
    AVAILABLE_TOOLS = {
        'web_search_preview': {
            'name': '–í–µ–±-–ø–æ–∏—Å–∫',
            'description': '–ü–æ–∏—Å–∫ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ',
            'pricing': '$25-50 –∑–∞ 1000 –∑–∞–ø—Ä–æ—Å–æ–≤'
        },
        'code_interpreter': {
            'name': '–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä –∫–æ–¥–∞', 
            'description': '–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Python –∫–æ–¥–∞, –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö, –≥—Ä–∞—Ñ–∏–∫–∏',
            'pricing': '–í–∫–ª—é—á–µ–Ω–æ –≤ —Å—Ç–æ–∏–º–æ—Å—Ç—å –º–æ–¥–µ–ª–∏'
        },
        'file_search': {
            'name': '–ü–æ–∏—Å–∫ –ø–æ —Ñ–∞–π–ª–∞–º',
            'description': '–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö',
            'pricing': '$2.50 –∑–∞ 1000 –∑–∞–ø—Ä–æ—Å–æ–≤ + $0.10/–ì–ë/–¥–µ–Ω—å'
        },
        'image_generation': {
            'name': '–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π',
            'description': '–°–æ–∑–¥–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é',
            'pricing': '–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ'
        },
        'computer_use_preview': {
            'name': 'Computer Use',
            'description': '–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º–∏',
            'pricing': '–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ'
        }
    }
    
    # ‚úÖ –ù–û–í–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ RESPONSES API
    MAX_CONVERSATION_RETENTION_DAYS = 90
    MIN_CONVERSATION_RETENTION_DAYS = 1
    DEFAULT_CONVERSATION_RETENTION_DAYS = 30
    
    # ‚úÖ REASONING EFFORT –î–õ–Ø O-SERIES –ú–û–î–ï–õ–ï–ô
    REASONING_EFFORTS = {
        'low': '–ù–∏–∑–∫–∏–π (–±—ã—Å—Ç—Ä–æ)',
        'medium': '–°—Ä–µ–¥–Ω–∏–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)',
        'high': '–í—ã—Å–æ–∫–∏–π (–≥–ª—É–±–æ–∫–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è)'
    }
    
    DEFAULT_REASONING_EFFORT = 'medium'
    
    # –õ–∏–º–∏—Ç—ã
    MAX_AGENT_NAME_LENGTH = 255
    MAX_AGENT_ROLE_LENGTH = 500
    MAX_SYSTEM_PROMPT_LENGTH = 8000
    MAX_VECTOR_STORES = 10
    
    # –¢–∞–π–º–∞—É—Ç—ã
    RESPONSE_TIMEOUT = 60
    STREAM_TIMEOUT = 120


class OpenAIResponsesValidator:
    """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Responses API"""
    
    @staticmethod
    def validate_agent_name(name: str) -> tuple[bool, str]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏–º–µ–Ω–∏ –∞–≥–µ–Ω—Ç–∞"""
        if not name or len(name.strip()) == 0:
            return False, "–ò–º—è –∞–≥–µ–Ω—Ç–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º"
        
        if len(name) > OpenAIResponsesConstants.MAX_AGENT_NAME_LENGTH:
            return False, f"–ò–º—è –∞–≥–µ–Ω—Ç–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ (–º–∞–∫—Å–∏–º—É–º {OpenAIResponsesConstants.MAX_AGENT_NAME_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤)"
        
        return True, ""
    
    @staticmethod
    def validate_agent_role(role: str) -> tuple[bool, str]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–æ–ª–∏ –∞–≥–µ–Ω—Ç–∞"""
        if not role or len(role.strip()) == 0:
            return False, "–†–æ–ª—å –∞–≥–µ–Ω—Ç–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π"
        
        if len(role) > OpenAIResponsesConstants.MAX_AGENT_ROLE_LENGTH:
            return False, f"–†–æ–ª—å –∞–≥–µ–Ω—Ç–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è (–º–∞–∫—Å–∏–º—É–º {OpenAIResponsesConstants.MAX_AGENT_ROLE_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤)"
        
        return True, ""
    
    @staticmethod
    def validate_system_prompt(prompt: str) -> tuple[bool, str]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
        if prompt and len(prompt) > OpenAIResponsesConstants.MAX_SYSTEM_PROMPT_LENGTH:
            return False, f"–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–º–∞–∫—Å–∏–º—É–º {OpenAIResponsesConstants.MAX_SYSTEM_PROMPT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤)"
        
        return True, ""
    
    @staticmethod
    def validate_model(model: str) -> tuple[bool, str]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
        if model not in OpenAIResponsesConstants.MODELS:
            return False, f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –º–æ–¥–µ–ª—å: {model}"
        
        return True, ""
    
    @staticmethod
    def validate_tools(tools: List[str]) -> tuple[bool, str]:
        """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        for tool in tools:
            if tool not in OpenAIResponsesConstants.AVAILABLE_TOOLS:
                return False, f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {tool}"
        
        return True, ""
    
    @staticmethod
    def validate_vector_store_ids(vector_store_ids: List[str]) -> tuple[bool, str]:
        """‚úÖ –ù–û–í–û–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â"""
        if len(vector_store_ids) > OpenAIResponsesConstants.MAX_VECTOR_STORES:
            return False, f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â (–º–∞–∫—Å–∏–º—É–º {OpenAIResponsesConstants.MAX_VECTOR_STORES})"
        
        for vs_id in vector_store_ids:
            if not vs_id or not isinstance(vs_id, str):
                return False, "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ID –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"
        
        return True, ""
    
    @staticmethod
    def validate_reasoning_effort(effort: str) -> tuple[bool, str]:
        """‚úÖ –ù–û–í–û–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
        if effort not in OpenAIResponsesConstants.REASONING_EFFORTS:
            return False, f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π: {effort}"
        
        return True, ""
    
    @staticmethod
    def validate_retention_days(days: int) -> tuple[bool, str]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        if not OpenAIResponsesConstants.MIN_CONVERSATION_RETENTION_DAYS <= days <= OpenAIResponsesConstants.MAX_CONVERSATION_RETENTION_DAYS:
            return False, f"–í—Ä–µ–º—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç {OpenAIResponsesConstants.MIN_CONVERSATION_RETENTION_DAYS} –¥–æ {OpenAIResponsesConstants.MAX_CONVERSATION_RETENTION_DAYS} –¥–Ω–µ–π"
        
        return True, ""
    
    @staticmethod
    def validate_create_request(request: OpenAIResponsesRequest) -> tuple[bool, str]:
        """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º—è
        valid, error = OpenAIResponsesValidator.validate_agent_name(request.agent_name)
        if not valid:
            return False, error
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–æ–ª—å
        valid, error = OpenAIResponsesValidator.validate_agent_role(request.agent_role)
        if not valid:
            return False, error
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if request.system_prompt:
            valid, error = OpenAIResponsesValidator.validate_system_prompt(request.system_prompt)
            if not valid:
                return False, error
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
        valid, error = OpenAIResponsesValidator.validate_model(request.model)
        if not valid:
            return False, error
        
        # ‚úÖ –ü–†–û–í–ï–†–Ø–ï–ú REASONING EFFORT
        valid, error = OpenAIResponsesValidator.validate_reasoning_effort(request.reasoning_effort)
        if not valid:
            return False, error
        
        # ‚úÖ –ü–†–û–í–ï–†–Ø–ï–ú VECTOR STORE IDS
        if request.vector_store_ids:
            valid, error = OpenAIResponsesValidator.validate_vector_store_ids(request.vector_store_ids)
            if not valid:
                return False, error
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è —Ö—Ä–∞–Ω–µ–Ω–∏—è
        valid, error = OpenAIResponsesValidator.validate_retention_days(request.conversation_retention)
        if not valid:
            return False, error
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
        if not 0 <= request.temperature <= 2:
            return False, "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç 0 –¥–æ 2"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º max_tokens
        if not 1 <= request.max_tokens <= 16000:
            return False, "max_tokens –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 1 –¥–æ 16000"
        
        # ‚úÖ –ü–†–û–í–ï–†–Ø–ï–ú LOGIC CONSISTENCY
        if request.enable_file_search and not request.vector_store_ids:
            return False, "–î–ª—è file_search –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å vector_store_ids"
        
        return True, ""


# ===== –£–õ–£–ß–®–ï–ù–ù–´–ï VECTOR STORE MODELS =====

@dataclass
class VectorStoreInfo:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ vector store —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π file_counts"""
    id: str
    name: str
    file_counts: dict
    status: str
    created_at: datetime
    expires_after: Optional[dict] = None
    
    @classmethod
    def from_openai_response(cls, response) -> 'VectorStoreInfo':
        """‚úÖ –ù–û–í–´–ô: –°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ OpenAI API —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        try:
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ file_counts
            file_counts_raw = getattr(response, 'file_counts', None)
            file_counts = cls._safe_extract_file_counts(file_counts_raw)
            
            return cls(
                id=response.id,
                name=response.name,
                file_counts=file_counts,
                status=getattr(response, 'status', 'unknown'),
                created_at=response.created_at if hasattr(response, 'created_at') else datetime.now(),
                expires_after=getattr(response, 'expires_after', None)
            )
        except Exception as e:
            logger.error("üí• Error creating VectorStoreInfo from response", error=str(e))
            # Fallback –¥–ª—è —Å–ª—É—á–∞—è –æ—à–∏–±–∫–∏
            return cls(
                id=getattr(response, 'id', 'unknown'),
                name=getattr(response, 'name', 'Unknown Store'),
                file_counts={"total": 0, "completed": 0, "in_progress": 0, "failed": 0},
                status='error',
                created_at=datetime.now()
            )
    
    @staticmethod
    def _safe_extract_file_counts(file_counts_obj) -> dict:
        """‚úÖ –ù–û–í–´–ô: –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è file_counts"""
        try:
            if file_counts_obj is None:
                return {"total": 0, "completed": 0, "in_progress": 0, "failed": 0}
            
            # –¢–∏–ø 1: –£–∂–µ —Å–ª–æ–≤–∞—Ä—å
            if isinstance(file_counts_obj, dict):
                return {
                    "total": file_counts_obj.get("total", 0),
                    "completed": file_counts_obj.get("completed", 0),
                    "in_progress": file_counts_obj.get("in_progress", 0),
                    "failed": file_counts_obj.get("failed", 0)
                }
            
            # –¢–∏–ø 2: –û–±—ä–µ–∫—Ç —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–ª—É—á–∞–π –¥–ª—è OpenAI SDK)
            result = {
                "total": getattr(file_counts_obj, 'total', 0),
                "completed": getattr(file_counts_obj, 'completed', 0),
                "in_progress": getattr(file_counts_obj, 'in_progress', 0),
                "failed": getattr(file_counts_obj, 'failed', 0)
            }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            if result["total"] == 0:
                result["total"] = getattr(file_counts_obj, 'count', 0)
            
            if result["completed"] == 0:
                for attr in ['processed', 'done', 'finished']:
                    if hasattr(file_counts_obj, attr):
                        result["completed"] = getattr(file_counts_obj, attr, 0)
                        break
            
            if result["in_progress"] == 0:
                for attr in ['processing', 'pending']:
                    if hasattr(file_counts_obj, attr):
                        result["in_progress"] = getattr(file_counts_obj, attr, 0)
                        break
            
            if result["failed"] == 0:
                for attr in ['error', 'cancelled']:
                    if hasattr(file_counts_obj, attr):
                        result["failed"] = getattr(file_counts_obj, attr, 0)
                        break
            
            return result
            
        except Exception as e:
            logger.error("üí• Error extracting file_counts", error=str(e))
            return {"total": 0, "completed": 0, "in_progress": 0, "failed": 0}
    
    def get_total_files(self) -> int:
        """–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤"""
        return self.file_counts.get('total', 0)
    
    def get_processed_files(self) -> int:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        return self.file_counts.get('completed', 0)
    
    def get_processing_files(self) -> int:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        return self.file_counts.get('in_progress', 0)
    
    def get_failed_files(self) -> int:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏"""
        return self.file_counts.get('failed', 0)
    
    def is_ready(self) -> bool:
        """–ì–æ—Ç–æ–≤ –ª–∏ vector store –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é"""
        return self.status == 'completed' or (
            self.get_total_files() > 0 and 
            self.get_processed_files() == self.get_total_files()
        )
    
    def get_processing_status(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        total = self.get_total_files()
        completed = self.get_processed_files()
        processing = self.get_processing_files()
        failed = self.get_failed_files()
        
        if total == 0:
            return "–ü—É—Å—Ç–æ"
        elif failed > 0:
            return f"–û—à–∏–±–∫–∏: {failed} –∏–∑ {total}"
        elif processing > 0:
            return f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {completed}/{total}"
        elif completed == total:
            return "–ì–æ—Ç–æ–≤–æ"
        else:
            return f"–ß–∞—Å—Ç–∏—á–Ω–æ: {completed}/{total}"


@dataclass
class VectorStoreFile:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ú–æ–¥–µ–ª—å —Ñ–∞–π–ª–∞ –≤ vector store"""
    id: str
    filename: str
    size: int
    created_at: datetime
    status: str
    vector_store_id: Optional[str] = None
    
    @classmethod
    def from_openai_response(cls, response, vector_store_id: str = None) -> 'VectorStoreFile':
        """‚úÖ –ù–û–í–´–ô: –°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ OpenAI API"""
        try:
            return cls(
                id=response.id,
                filename=getattr(response, 'filename', 'unknown'),
                size=getattr(response, 'bytes', getattr(response, 'size', 0)),
                created_at=response.created_at if hasattr(response, 'created_at') else datetime.now(),
                status=getattr(response, 'status', 'unknown'),
                vector_store_id=vector_store_id
            )
        except Exception as e:
            logger.error("üí• Error creating VectorStoreFile from response", error=str(e))
            return cls(
                id=getattr(response, 'id', 'unknown'),
                filename='Error File',
                size=0,
                created_at=datetime.now(),
                status='error'
            )
    
    def get_size_mb(self) -> float:
        """–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë"""
        return round(self.size / (1024 * 1024), 2) if self.size > 0 else 0.0
    
    def is_processed(self) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∞–Ω –ª–∏ —Ñ–∞–π–ª"""
        return self.status in ['completed', 'processed', 'done']
    
    def is_processing(self) -> bool:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª"""
        return self.status in ['processing', 'in_progress', 'pending']
    
    def has_error(self) -> bool:
        """–ï—Å—Ç—å –ª–∏ –æ—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ"""
        return self.status in ['failed', 'error', 'cancelled']


@dataclass 
class FileUploadResult:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞"""
    success: bool
    file_id: Optional[str] = None
    filename: Optional[str] = None
    size: Optional[int] = None
    error: Optional[str] = None
    vector_store_id: Optional[str] = None
    
    @classmethod
    def success_result(cls, file_id: str, filename: str, size: int, vector_store_id: str = None):
        return cls(
            success=True,
            file_id=file_id,
            filename=filename,
            size=size,
            vector_store_id=vector_store_id
        )
    
    @classmethod
    def error_result(cls, error: str):
        return cls(success=False, error=error)
    
    def get_size_mb(self) -> float:
        """–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë"""
        return round(self.size / (1024 * 1024), 2) if self.size else 0.0
